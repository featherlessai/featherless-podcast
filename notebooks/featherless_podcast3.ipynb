{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featherless.ai - Roleplaying LLM-Enhanced Podcast Generator\n",
    "\n",
    "This notebook transforms extracted text into a dynamic, engaging podcast script using a fine-tuned roleplaying LLM. Leveraging Featherless.ai's access to open-weight LLMs on Hugging Face, it:\n",
    "\n",
    "1. **Creates vibrant dialogue**: Uses a roleplaying LLM to infuse conversations with personality and flair.\n",
    "2. **Defines distinct characters**: Speaker 1 as a captivating teacher and Speaker 2 as a curious, expressive learner.\n",
    "3. **Adds natural interactions**: Incorporates interruptions, reactions, and expressive language for a lively exchange.\n",
    "4. **Ensures TTS readiness**: Outputs a structured list of tuples tailored for TTS systems with controlled expressions.\n",
    "\n",
    "The result is a podcast script that captivates listeners while remaining compatible with text-to-speech processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt Engineering\n",
    "\n",
    "This specialized prompt is designed for TTS compatibility and structured output:\n",
    "\n",
    "- Establishes speaker roles and personalities\n",
    "- Controls speech characteristics (fillers, expressions, etc.)\n",
    "- Specifies exact output format (list of tuples)\n",
    "- Includes detailed instructions for natural dialogue flow\n",
    "- Provides TTS-specific constraints (Speaker 1 cannot do \"umms\", Speaker 2 can)\n",
    "\n",
    "The prompt includes specific formatting requirements to ensure the output is both engaging for humans and processable by TTS systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an international Oscar-winning screenwriter who has worked with multiple award-winning podcasters.\n",
    "\n",
    "Your job is to rewrite the provided podcast transcript for an AI Text-To-Speech pipeline. The original transcript was written by a less experienced AI, so you need to enhance it significantly.\n",
    "\n",
    "Create an engaging dialogue between two speakers, each with distinct personalities:\n",
    "\n",
    "- Speaker 1: A captivating teacher who leads the conversation, explains concepts with vivid analogies and personal anecdotes, and makes the topic accessible and memorable. They speak clearly and confidently, without using filler words like \"umm\" or \"hmm.\"\n",
    "- Speaker 2: A curious and enthusiastic learner who keeps the conversation on track by asking follow-up questions. They often get excited or confused, expressing their reactions verbally with phrases like \"That's fascinating!\", \"Wait, I'm not sure I get that,\" or \"Wow, that's like [analogy].\"\n",
    "\n",
    "The conversation should include:\n",
    "\n",
    "- Realistic anecdotes and analogies to illustrate key points.\n",
    "- Wild or interesting tangents from Speaker 2, making connections to everyday experiences or popular culture.\n",
    "- Occasional interruptions from Speaker 2 with questions or comments, creating a natural flow.\n",
    "\n",
    "Start with a fun, catchy introduction to hook the listeners.\n",
    "\n",
    "Return the dialogue as a list of tuples, like this:\n",
    "\n",
    "[\n",
    "    (\"Speaker 1\", \"Text here\"),\n",
    "    (\"Speaker 2\", \"Text here\"),\n",
    "    ...\n",
    "]\n",
    "\n",
    "Begin directly with the dialogue, no additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Configuration\n",
    "\n",
    "These parameters configure our connection to the Featherless AI API:\n",
    "- The base URL for API requests\n",
    "- Your API key for authentication\n",
    "- The specific model to use for content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.featherless.ai/v1\"\n",
    "FEATHERLESS_API_KEY = \"YOUR_FEATHERLESS_API_KEY\" # Available in https://featherless.ai/account/api-keys\n",
    "DEFAULT_MODEL =  \"EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2\" # Go through our model catalog on https://featherless.ai/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Explanation\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `BASE_URL` | The Featherless AI API endpoint URL |\n",
    "| `FEATHERLESS_API_KEY` | Your personal API key for authentication |\n",
    "| `DEFAULT_MODEL` | The model used for podcast generation (`Qwen/Qwen2.5-72B-Instruct` is selected for its strong instruction-following capabilities) |\n",
    "| `max_tokens` | Maximum number of tokens in the response (4000 allows for comprehensive dialogue) |\n",
    "| `temperature` | Set to 1 for creative, natural-sounding dialogue variation |\n",
    "\n",
    "The higher temperature setting helps ensure the conversation sounds natural and varied rather than robotic or overly predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "from typing import Optional\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "This function handles reading the extracted text from a file with proper error handling and encoding detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(filename):\n",
    "    # Try UTF-8 first (most common encoding for text files)\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except UnicodeDecodeError:\n",
    "        # If UTF-8 fails, try with other common encodings\n",
    "        encodings = ['latin-1', 'cp1252', 'iso-8859-1']\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                with open(filename, 'r', encoding=encoding) as file:\n",
    "                    content = file.read()\n",
    "                print(f\"Successfully read file using {encoding} encoding.\")\n",
    "                return content\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        print(f\"Error: Could not decode file '{filename}' with any common encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not read file '{filename}'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podcast Generation Function\n",
    "\n",
    "This function takes the system prompt and input text and generates TTS-ready podcast content in the specified structured format. The output is designed to be:\n",
    "\n",
    "1. Easy to parse programmatically (list of tuples)\n",
    "2. Ready for voice synthesis with proper speaker attribution\n",
    "3. Optimized for the limitations of TTS systems (controlled expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_podcast(system_prompt, input_prompt):\n",
    "    \"\"\"\n",
    "    Generate TTS-ready podcast content using Featherless AI API\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    system_prompt : str\n",
    "        The system prompt that defines behavior, output format, and TTS constraints\n",
    "    input_prompt : str\n",
    "        The extracted text content to transform into structured dialogue\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The generated podcast content formatted as a list of tuples for TTS processing\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": input_prompt},\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/chat/completions\",\n",
    "            headers={\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {FEATHERLESS_API_KEY}\"\n",
    "            },\n",
    "            json={\n",
    "                \"model\": DEFAULT_MODEL,\n",
    "                \"messages\": messages,\n",
    "                \"max_tokens\": 4000,\n",
    "                \"temperature\": 0.8,\n",
    "                \"min_p\": 0.05,\n",
    "                \"repetition_penalty\": 1.03\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating podcast content: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Process\n",
    "\n",
    "The following cell:\n",
    "1. Reads the input text file that was processed in the previous notebook\n",
    "2. Generates structured podcast content with the LLM\n",
    "3. Saves the result to a file with proper encoding\n",
    "4. Provides a preview of the generated content's beginning and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input prompt\n",
    "INPUT_PROMPT = read_file_to_string('./extracted_text.txt')\n",
    "\n",
    "# Generate podcast content\n",
    "podcast_content = generate_podcast(SYSTEM_PROMPT, INPUT_PROMPT)\n",
    "\n",
    "if podcast_content:\n",
    "    # Save the generated content\n",
    "    with open('new_generated_podcast.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(podcast_content)\n",
    "    print(\"Generated podcast content has been saved to generated_podcast.txt\")\n",
    "    \n",
    "    # Preview the content\n",
    "    print(\"\\nPreview of generated content:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(podcast_content[:1000])\n",
    "    print(\"\\n...\\n\")\n",
    "    print(podcast_content[-1000:])\n",
    "else:\n",
    "    print(\"Failed to generate podcast content\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
